---
layout: post
title: Can We Use Machine Learning to Predict The Winning Team In League of Legends?
subtitle: Unit 2 Build Project And Blog Post
gh-repo: AidanMahoney73/DS-Unit-2-Applied-Modeling
gh-badge: [star, fork, follow]
tags: [test]
comments: true
---

## What is League of Legends
{: style="text-align: center;"}

League of Legends is a free to play online game where 2 teams face off against one another in hopes of beating the other in combat. First teams take turns picking and banning characters for the game. These characters have unique abilities and stats and players can choose items and spells as well.

## Data Processing
{: style="text-align: center;"}

To use machine learning on this problem I selected the winning team to be my target so that I could use the characters as my features. I found a DataFrame with nearly 50k rated games and sifted through it to train a Baseline model, Ridge Regression, and a Catboost model. In the data, there were columns that had scores and details regarding the played games that would aid in predicting the winner, so those columns were removed so as to ensure data leakage would be avoided

When training and validated to models I used the ROC AUC metric as it gives results in a percentage format (useful due to my Catboost model and Ridge Regression model using different number scales) and is compatible with linear models, unlike the sklearn accuracy metric. To make the baseline model I took the winners column and selected the team with the most wins to always predict as the winner. This yielded a ROC AUC score of .5 exactly. Upon training the linear model and getting the score of the validation set it yielded about .53525. This isn’t great but since its a binary classification problem the Catboost model should have an easier time making sense of the data. Unfortunately, the Catboost model only got about .5358 which is only just barely higher than the ridge regression model.

The Features are explaining very little about the data

![Unit 2 (2).png](/img/Unit 2 (2).png)

And the predictions the machine does make are very weak

![Unit 2 (3).png](/img/Unit 2 (3).png)

![Unit 2 (4).png](/img/Unit 2 (4).png)

Interestingly the model is better at prediction when team 1 will win than team 2. I believe maybe this is because of the Pick and Ban order of the game and how characters are decided in the first place

![Unit 2 (1).png](/img/Unit 2 (1).png)

This model doesn’t seem useful for team predictions and the data given isn’t enough to grasp how the game will turn out. There are too many invisible factors such as player skill and team communication. Running the final test score on the Catboost model (my best model of the mix) I got a score of about .52681 which is a further decrease from the validation scores.



[My Google Colab Notebook](https://colab.research.google.com/drive/1UyedcObWwtZOhqvbC0cFJhqmHkkPg_AG)
{: style="text-align: center;"}
